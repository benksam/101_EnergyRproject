# Let's look at a histogram
ggplot(data=inpatient) +
geom_histogram(mapping=aes(x=AverageCharges))
# Read in the Medicare payments dataset
names <- c("DRG", "ProviderID", "Name", "Address", "City", "State", "ZIP", "Region", "Discharges", "AverageCharges", "AverageTotalPayments",
"AverageMedicarePayments")
ggplot(data=highCharges) +
geom_point(mapping=aes(DRG,AverageCharges)) +
theme(axis.text.x = element_text(angle = 90, vjust = 1, hjust=1))
library(ggplot2)
ggplot(data=highCharges) +
geom_point(mapping=aes(DRG,AverageCharges)) +
theme(axis.text.x = element_text(angle = 90, vjust = 1, hjust=1))
types = 'ccccccccinnn'
inpatient <- read_tsv('http://594442.youcanlearnit.net/inpatient.tsv', col_names = names, skip=1, col_types = types)
# Load the tidyverse
library(tidyverse)
# Read in the Medicare payments dataset
names <- c("DRG", "ProviderID", "Name", "Address", "City", "State", "ZIP", "Region", "Discharges", "AverageCharges", "AverageTotalPayments",
"AverageMedicarePayments")
types = 'ccccccccinnn'
inpatient <- read_tsv('http://594442.youcanlearnit.net/inpatient.tsv', col_names = names, skip=1, col_types = types)
# Let's look at a histogram
ggplot(data=inpatient) +
geom_histogram(mapping=aes(x=AverageCharges))
# Load the tidyverse
library(tidyverse)
# Read in the Pew dataset
pew <- read_csv("http://594442.youcanlearnit.net/pew.csv")
# Let's take a look at what we have
pew
View(pew)
# This looks to be a gathering problem.  Our dataset is wide and we want it to be long.
# The gather function can take care of that for us
pew.long <- gather(pew, income, freq, -religion)
# And what did we get?
View(pew.long)
# Read the dataset
weather <- read_csv("http://594442.youcanlearnit.net//mexicanweather.csv")
weather <- read_csv("Data/weather.csv")
# Let's look at what we have
View(weather)
# And use spread() to make it wider
weather.wide <- spread(weather, element, value)
# Load the tidyverse
library(tidyverse)
# And use spread() to make it wider
weather.wide <- spread(weather, element, value)
colnames(weather)
weather.long <- gather(weather, days,
value,-c("station","year","month","element"))
View(weather.long)
weather.wide <- spread(weather, element, value)
weather.wide <- spread(weather.long, element, value)
# Where are we now?
View(weather.wide)
View(pew.long)
foulshots <- c(18, 22, 15, 13, 5)
sum(foulshots)
foulshot_strings <- c("18", "22", "15", "13", "5")
sum(foulshot_strings)
class(foulshot_strings)
class(foulshot)
class(foulshots)
foulshot_converted <- as.numeric(foulshot_strings)
class(foulshot_converted)
sum(foulshot_converted)
is.numeric(foulshots)
is.character(foulshots)
is.numeric(foulshot_strings)
is.character(foulshot_strings)
names <- c("Mike", "Rae", "Dennis", "Sally", "Ian", "Sue")
teams <- c(1,1,1,2,2,2)
assignments <- tibble(names, teams)
assignments
assignments$teams <- as.factor(assignments$teams)
assignments
is.factor(assignments$names)
is.factor(assignments$teams)
# Read the dataset
weather <- read_csv("http://594442.youcanlearnit.net//mexicanweather.csv")
weather <- read_csv("Data/weather.csv")
library(lubridate)
# Let's look at what we have
weather
weather <- read_csv("http://594442.youcanlearnit.net//mexicanweather.csv")
# Read the dataset
### CHANGE THIS URL!!!
weather <- read_csv("https://s3.amazonaws.com/msba-70200/mexicanweather.csv")
# We can also extract some derived values such as the weekday
wday("2018-04-01")
year(weather$date)
year(date)
date = "2018-04-01"
class(date)
date=as.Date(date)
year(date)
month(date)
day(date)
# or day of the year
yday("2018-04-01")
# We can also extract some derived values such as the weekday
wday("2018-04-01")
mdy("04/01/2018")
mdy("04/01/18")
dmy("04/01/18")
ymd("2018-04-01")
ymd_hms("2018-04-01 08:00:00")
class(ymd_hms("2018-04-01 08:00:00"))
# And we can include times
fecha = ymd_hms("2018-04-01 08:00:00")
year(fecha)
month(fecha)
day(fecha)
hour(fecha)
ymd_hms("2018-04-01 08:00:00", tz='EST')
library(ggplot2)
inpatient <- read_csv("Data/inpatient_short.csv")
types = 'ccccccccinnn'
inpatient <- read_csv("Data/inpatient_short.csv",
col_names = names, skip=1, col_types = types)
inpatient <- read_csv("Data/inpatient_short.csv")
View(inpatient)
names <- c("DRG", "ProviderID", "Name", "Address", "City", "State", "ZIP", "Region", "Discharges", "AverageCharges", "AverageTotalPayments",
"AverageMedicarePayments")
types = 'ccccccccinnn'
inpatient
inpatient <- read_csv("Data/inpatient_short.csv",
col_names = names, col_types = types)
inpatient
inpatient <- read_csv("Data/inpatient_short.csv")
inpatient <- read_csv("Data/inpatient_short.csv",
col_types = types)
inpatient
ggplot(data=inpatient) +
geom_histogram(mapping=aes(x=AverageCharges))
library(ggplot2)
# Let's look at a histogram
ggplot(data=inpatient) +
geom_histogram(mapping=aes(x=AverageCharges))
detach("package:ggplot2", unload=TRUE)
detach("package:tidyverse", unload=TRUE)
# Load the tidyverse
library(tidyverse)
library(ggplot2)
types = 'ccccccccinnn'
inpatient <- read_csv("Data/inpatient_short.csv",
col_types = types) # skip=1, col_names = names,
ggplot(data=inpatient) +
geom_histogram(mapping=aes(x=AverageCharges))
#
inpatient
"AverageMedicarePayments")
names <- c("DRG", "ProviderID", "Name", "Address", "City",
"State", "ZIP", "Region", "Discharges",
"AverageCharges", "AverageTotalPayments",
"AverageMedicarePayments")
colnames(inpatient)
colnames(inpatient) = names
inpatient
ggplot(data=inpatient) +
geom_histogram(mapping=aes(x=AverageCharges))
# Load the tidyverse
library(tidyverse)
library(ggplot2)
ggplot(data=inpatient) +
geom_histogram(mapping=aes(x=AverageCharges))
ggplot(data=inpatient) +
geom_histogram(mapping=aes(x=AverageCharges)) +
coord_cartesian(ylim=c(0,25))
ggplot(data=inpatient) +
geom_boxplot(mapping=aes("charges",AverageCharges))
ggplot(data=inpatient) +
geom_boxplot(mapping=aes(State,AverageCharges))
ggplot(data=inpatient) +
geom_histogram(mapping=aes(x=AverageCharges))
highCharges <- filter(inpatient, AverageCharges>500000)
highCharges <- filter(inpatient, AverageCharges>50000)
ggplot(data=highCharges) +
geom_point(mapping=aes(DRG,AverageCharges)) +
theme(axis.text.x = element_text(angle = 90, vjust = 1, hjust=1))
unique(highCharges$DRG)
lowCharges <- filter(inpatient, AverageCharges<50000)
unique(lowCharges$DRG)
ggplot(data=lowCharges) +
geom_boxplot(mapping=aes(State,AverageCharges))
ggplot(data=highCharges) +
geom_point(mapping=aes(State,AverageCharges)) +
theme(axis.text.x = element_text(angle = 90, vjust = 1, hjust=1))
inspections <- read_csv("Data/inspections.csv",
col_names=names, skip=1)
# Look at a summary of the data
summary(inpatient)
badmath <- c(1,2,3,4/0,0/0,NA)
badmath
is.na(badmath)
is.nan(badmath)
is.infinite(badmath)
is.finite(badmath)
unique(inpatient$DRG)
inpatient
View(inpatient)
# Let's try separating this on the hyphen
inpatient_separate <- separate(inpatient,DRG,c('DRGcode','DRGdescription'),'-')
View(inpatient_separate)
head(inpatient_separate)
# Let's try separating this on the hyphen
inpatient_separateS <- separate(inpatient,DRG,c('DRGcode','DRGdescription'),'-')
inpatient_separate = NULL
# Let's separate with character position instead
inpatient_separateP <- separate(inpatient,DRG,c('DRGcode','DRGdescription'),4)
View(inpatient_separateP)
# And take a look at the data now
glimpse(inpatient_separate)
# And take a look at the data now
glimpse(inpatient_separateP)
glimpse(inpatient_separateS)
glimpse(inspections)
View(inspections)
names <- c("ID", "DBAName", "AKAName", "License", "FacilityType", "Risk", "Address",
"City", "State", "ZIP", "InspectionDate", "InspectionType", "Results",
"Violations", "Latitude","Longitude","Location")
colnames(inspections) = names
# And take a look at the unique regions
unique(regional_inspections$Region)
unique(inspections$Region)
inspections$Region <- str_to_upper(regional_inspections$Region)
inspections$Region <- str_to_upper(inspections$Region)
unique(inspections$Region)
inspections$Region <- str_replace(inspections$Region,'CCHICAGO, IL', 'CHICAGO, IL')
inspections$Region <- str_replace(inspections$Region,'CHCICAGO, IL', 'CHICAGO, IL')
inspections$Region <- str_replace(inspections$Region,'CHICAGOCHICAGO, IL', 'CHICAGO, IL')
inspections$Region <- str_replace(inspections$Region,'CHCHICAGO, IL', 'CHICAGO, IL')
inspections$Region <- str_replace(inspections$Region,'CHICAGOI, IL', 'CHICAGO, IL')
unique(inspections$Region)
# Let's take care of a few misspellings of Chicago
inspections$Region <- str_replace(inspections$Region,'CCHICAGO, IL', 'CHICAGO, IL')
inspections$Region <- str_replace(inspections$Region,'CHCICAGO, IL', 'CHICAGO, IL')
inspections$Region <- str_replace(inspections$Region,'CHICAGOCHICAGO, IL', 'CHICAGO, IL')
inspections$Region <- str_replace(inspections$Region,'CHCHICAGO, IL', 'CHICAGO, IL')
inspections$Region <- str_replace(inspections$Region,'CHICAGOI, IL', 'CHICAGO, IL')
unique(inspections$Region)
# Let's take care of a few misspellings of Chicago
inspections$Region <- str_replace(inspections$Region,'CCHICAGO', 'CHICAGO')
inspections$Region <- str_replace(inspections$Region,'CHCICAGO', 'CHICAGO')
inspections$Region <- str_replace(inspections$Region,'CHICAGOCHICAGO', 'CHICAGO')
inspections$Region <- str_replace(inspections$Region,'CHCHICAGO', 'CHICAGO')
inspections$Region <- str_replace(inspections$Region,'CHICAGOI', 'CHICAGO')
unique(inspections$Region)
# And take a look at the data now
glimpse(inpatient_separateP)
# Trim the DRGcode field
inpatient_separateP$DRGcode <- str_trim(inpatient_separateP$DRGcode)
glimpse(inpatient_separate)
glimpse(inpatient_separateP)
# Read in the coal dataset
coal <- read_csv("Data/coal.csv")
View(coal)
# Read in the coal dataset
coal <- read_csv("Data/coal.csv", skip=2)
View(coal)
colnames(coal)
View(coal)
# Rename the first column as region
colnames(coal)[1] <- "region"
View(coal)
summary(coal)
str(coal)
glimpse(coal)
View(coal)
# Convert from a wide dataset to a long dataset using gather
coal_long <- gather(coal, 'year', 'coal_consumption', -region)
glimpse(coal_long)
View(coal_long)
glimpse(coal_long)
# Convert years to integers
coal_long$year <- as.integer(coal_long$year)
summary(coal_long)
glimpse(coal_long)
# Convert coal consumption to numeric
coal_long$coal_consumption <- as.numeric(coal_long$coal_consumption)
summary(coal_long)
# Look at region values - they contain both continents and countries
unique(coal_long$region)
noncountries <- c("North America", "Central & South America", "Antarctica", "Europe", "Eurasia",
"Middle East", "Africa", "Asia & Oceania", "World")
which(coal_long$region in noncountries)
which(coal_long$region %in% noncountries)
fit = which(coal_long$region %in% noncountries)
match(coal_long$region, noncountries)
which(!is.na(match(coal_long$region, noncountries)))
matches == fit
# Look for matches
matches <- list(which(!is.na(match(coal_long$region, noncountries))))
fit = list(which(coal_long$region %in% noncountries))
matches == fit
matches = fit
matches <- list(which(!is.na(match(coal_long$region, noncountries))))
fit = list(which(coal_long$region %in% noncountries))
matches != fit
# Look for matches
matches <- which(!is.na(match(coal_long$region, noncountries)))
fit = which(coal_long$region %in% noncountries)
matches != fit
whicn(matches != fit)
which(matches != fit)
which(matches == fit)
matches == fit
# create a tibble of country values
coal_country <- coal_long[-matches,]
# create a tibble of regional values
coal_region <- coal_long[matches,]
# check them out
unique(coal_region$region)
# Start with a scatterplot
ggplot(data=coal_region, mapping=aes(x=year, y=coal_consumption)) +
geom_point()
ggplot(data=coal_region, mapping=aes(x=year, y=coal_consumption)) +
geom_line()
ggplot(data=coal_region, mapping=aes(x=year, y=coal_consumption)) +
geom_line(mapping=aes(color=region))
# Load in the libraries that we'll need
library(tidyverse)
library(stringr)
library(lubridate)
# Read in the dataset
water <- read_csv('http://594442.youcanlearnit.net/austinwater.csv')
water <- read_csv("Data/austinwater_short.csv")
View(austinwater)
View(water)
# Let's take a look at what we have
glimpse(water)
colnames(water)
water1 = water[,c(3,4,2,6,7,9,10)]
water0 <- tibble('siteName'=water$SITE_NAME,
'siteType'=water$SITE_TYPE,
'sampleTime'=water$SAMPLE_DATE,
'parameterType'=water$PARAM_TYPE,
'parameter'=water$PARAMETER,
'result'=water$RESULT,
'unit'=water$UNIT)
summary(water0)
summary(water1)
glimpse(water)
unique(water$parameter)
colnames(water)
unique(water0$parameter)
unique(water0$parameterType)
filtered_water <- subset(water0,(parameterType=='Alkalinity/Hardness/pH') |
parameterType=='Conventionals')
unique(filtered_water$parameter)
filtered_water0 <- subset(water0,(parameterType=='Alkalinity/Hardness/pH') |
parameterType=='Conventionals')
unique(filtered_water0$parameter)
unique(water0[which(str_detect(water$parameter,'PH')),]$parameter)
unique(water[which(str_detect(water$parameter,'PH')),]$parameter)
water <- tibble('siteName'=water$SITE_NAME,
'siteType'=water$SITE_TYPE,
'sampleTime'=water$SAMPLE_DATE,
'parameterType'=water$PARAM_TYPE,
'parameter'=water$PARAMETER,
'result'=water$RESULT,
'unit'=water$UNIT)
unique(water[which(str_detect(water$parameter,'PH')),]$parameter)
unique(water$parameterType)
filtered_water <- subset(water,(parameterType=='Alkalinity/Hardness/pH') |
parameterType=='Conventionals')
unique(filtered_water$parameter)
filtered_water <- subset(filtered_water, ((parameter=='PH') |
(parameter=='WATER TEMPERATURE')))
filtered_water <- subset(water,(parameterType=='Alkalinity/Hardness/pH') |
parameterType=='Conventionals')
filtered_water = filtered_water %>%
filter((parameter=='PH') |
(parameter=='WATER TEMPERATURE'))
glimpse(filtered_water)
# Let's take a look at the data a different way
summary(filtered_water)
filtered_water$siteType <- as.factor(filtered_water$siteType)
filtered_water$parameterType <- as.factor(filtered_water$parameterType)
filtered_water$parameter <- as.factor(filtered_water$parameter)
filtered_water$unit <- as.factor(filtered_water$unit)
summary(filtered_water)
glimpse(filtered_water)
# And sampleTime should be a date/time object
filtered_water$sampleTime <- mdy_hms(filtered_water$sampleTime)
mdy_hms(filtered_water$sampleTime)
filtered_water$sampleTime
# Let's take a look at the data a different way
summary(filtered_water)
# Why are some of these measurements in feet?
subset(filtered_water,unit=='Feet')
summary(filtered_water)
ggplot(filtered_water,mapping=aes(x=sampleTime, y=result)) +
geom_point()
ggplot(data=filtered_water, mapping = aes(x=unit,y=result)) + geom_boxplot()
filtered_water$unit=='Deg. Fahrenheit'
# Let's find our Fahrenheit values in the dataset
fahrenheit <- which(filtered_water$unit=='Deg. Fahrenheit')
fahrenheit
(filtered_water$result[fahrenheit] - 32) * (5/9)
# And convert them to Celsius
filtered_water$result[fahrenheit] <- (filtered_water$result[fahrenheit] - 32) * (5/9)
# Let's look at a final summary of the data
summary(filtered_water)
# We just need to fix up the unit values
filtered_water$unit[fahrenheit] <- 'Deg. Celsius'
summary(filtered_water)
# There are some empty factor levels in there, let's get rid of them
filtered_water$unit <- droplevels(filtered_water$unit)
summary(filtered_water)
# Now how do our boxplots look?
ggplot(data=filtered_water, mapping = aes(x=unit,y=result)) + geom_boxplot()
# Start the spread by looking at the data
summary(filtered_water)
# Get rid of parameterType and unit
filtered_water <- filtered_water[,-c(4,7)]
filtered_water
# Try a spread
filtered_water_wide <- spread(filtered_water,parameter,result)
filtered_water_dup = filtered_water[,-4:5]
filtered_water_dup = filtered_water[,-c(4,5)]
duplicated(filtered_water_dup)
which(duplicated(filtered_water_dup))
filtered_water_dup = filtered_water[,-c(5)]
u
which(duplicated(filtered_water_dup))
filtered_water
filtered_water_nodup = filtered_water[-19,]
# Try a spread
filtered_water_wide <- spread(filtered_water_nodup,parameter,result)
View(filtered_water_wide)
# and i'll just clean up those column names
colnames(filtered_water_wide)[4] <- 'pH'
colnames(filtered_water_wide)[4] <- 'temperature'
View(filtered_water_wide)
# and i'll just clean up those column names
colnames(filtered_water_wide)[4] <- 'pH'
colnames(filtered_water_wide)[4] <- 'temperature'
filtered_water_wide
# What are those duplicate rows all about?
# Let's look at a few
filtered_water[c(49274, 49342,49219,49284),]
ssa <- read_csv("Data/ssadisability.csv")
View(ssadisability)
View(ssa)
# Take a look at how this was imported
glimpse(ssa)
# Make the dataset long
ssa_long <- gather(ssa, month, applications, -Fiscal_Year)
# And what do we get?
print(ssa_long, n=20)
head(ssa_long, n=20)
# Split the month and application type
ssa_long <- separate(ssa_long, month, c("month", "application_method"), sep="_")
# What does that look like?
print(ssa_long, n=20)
# What values do we have for months?
unique(ssa_long$month)
# What values do we have for months?
unique(ssa_long$month)
ssa_long$month = ssa_long$month %>%
str_sub(1,3)
# What values do we have for months?
unique(ssa_long$month)
# What values do we now have for months and years?
unique(ssa_long$month)
# Convert Fiscal_Year from alphanumeric strings to actual years
ssa_long$Fiscal_Year <- str_replace(ssa_long$Fiscal_Year, "FY", "20")
unique(ssa_long$Fiscal_Year)
# What does that look like?
print(ssa_long, n=20)
# What values do we now have for months?
unique(ssa_long$Fiscal_Year)
# Build a date string using the first day of the month
paste('01', ssa_long$month, ssa_long$Fiscal_Year)
ssa_long$Date <- dmy(paste("01", ssa_long$month, ssa$Fiscal_Year))
# What does that look like?
print(ssa_long, n=20)
# What do those look like?
unique(ssa_long$Date)
which(month(ssa_long$Date)>=10
)
# Let's find the affected rows
advanced_dates <- which(month(ssa_long$Date)>=10)
year(ssa_long$Date[advanced_dates]) - 1
year(ssa_long$Date[advanced_dates])
# And then decerement the years by one
year(ssa_long$Date[advanced_dates]) <- year(ssa_long$Date[advanced_dates]) - 1
year(ssa_long$Date[advanced_dates])
# Let's look at where we are
summary(ssa_long)
# Remove Fiscal_Year and month columns
ssa_long$Fiscal_Year <- NULL
ssa_long$month <- NULL
# Convert application_method to a factor
ssa_long$application_method <- as.factor(ssa_long$application_method)
# How does that look
summary(ssa_long)
# Widen the final dataset
ssa <- spread(ssa_long, application_method, applications)
# And take a look
print(ssa,n=20)
# Add a column for the percentage of applications that were online
ssa$online_percentage <- ssa$Internet/ssa$Total*100
# And take a look
print(ssa,n=20)
# Plot the results
ggplot(data=ssa, mapping=aes(x=Date,y=online_percentage)) +
geom_point()
